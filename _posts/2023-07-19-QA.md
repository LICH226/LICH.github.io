---
layout: post
title: 机器问答
date: 2023-07-19
author: YMieMie
tags: [nlp, Question-Answering]
comments: true
---

一篇机器问答的笔记



# Question-Answering  机器问答

课程链接：[百度AI Studio课程_学习成就梦想，AI遇见未来_AI课程 - 百度AI Studio - 人工智能学习与实训社区 (baidu.com)](https://aistudio.baidu.com/aistudio/education/lessonvideo/1000421)

[![pCTcL4O.md.png](https://s1.ax1x.com/2023/07/18/pCTcL4O.md.png)](https://imgse.com/i/pCTcL4O)

## Answer

### Answer is simply  a word

bAbI： MNIST of QA  20种问题

chaining facts, simple induction deduction,etc.

[![pCTcbE6.md.png](https://s1.ax1x.com/2023/07/18/pCTcbE6.md.png)](https://imgse.com/i/pCTcbE6)

### Multiple Choices

[![pCTc7Hx.md.png](https://s1.ax1x.com/2023/07/18/pCTc7Hx.md.png)](https://imgse.com/i/pCTc7Hx)

### Span in Source / Extraction-based

原文摘抄 选取start和end分数最高的

SQuAD             DRCD中文版

[![pCTcouR.md.png](https://s1.ax1x.com/2023/07/18/pCTcouR.md.png)](https://imgse.com/i/pCTcouR)

### Free Answer Generation

没有限制



MS　当作Span in Source / Extraction-based硬解

### Know what you don't know

测验机器不回答问题的能力，有的问题在文章中没有答案

SQuAD 2.0



在source中加入一个【NULL】的token，如果【NULL】的分数最大（超过一个阈值就可以，不一定要分数最大），那么就没有正确答案，在BERT中，用【CLS】替代了【NULL】

[![pCTcTD1.md.png](https://s1.ax1x.com/2023/07/18/pCTcTD1.md.png)](https://imgse.com/i/pCTcTD1)

也可以直接再加一个Answer Verifier模型来进行分类Yes/No

[![pCTcXCD.md.png](https://s1.ax1x.com/2023/07/18/pCTcXCD.md.png)](https://imgse.com/i/pCTcXCD)

## Knowledge Source

***DrQA***

Knowledge Source 来源是整个Internet，因此，我们不知道Document是哪一篇，因此将QA问题拆成两个部分，首先是文章检索，在文章资料库找到相关的文章，第二步根据相关的文章去找出问题的答案。

[![pCTcqUK.md.png](https://s1.ax1x.com/2023/07/18/pCTcqUK.md.png)](https://imgse.com/i/pCTcqUK)



QA_model需要做出额外的判断来判断这个被检索的文章是不是可靠。

[![pCTcj8e.md.png](https://s1.ax1x.com/2023/07/18/pCTcj8e.md.png)](https://imgse.com/i/pCTcj8e)

### Visual

图片，影像，声音，使用CNN和pretrained来生成embedding，后面的模型架构相似。

**Movie QA  文字，影像咨询**

## Question

### Simple Question : Match & Extract

只需两步解决问题 match & extract

[![pC7AFoj.md.png](https://s1.ax1x.com/2023/07/19/pC7AFoj.md.png)](https://imgse.com/i/pC7AFoj)

#### Query-to-context Attention

[![pC7AiwQ.md.png](https://s1.ax1x.com/2023/07/19/pC7AiwQ.md.png)](https://imgse.com/i/pC7AiwQ)

#### 一些QA的模型架构

Context2Query & Query2Context

<u>*End-to-end Memory Network*</u>

<u>*R-Net*</u>

*<u>BiDAF</u>*

<u>*QA-Net*</u>

#### BERT

[![pC7APeg.md.png](https://s1.ax1x.com/2023/07/19/pC7APeg.md.png)](https://imgse.com/i/pC7APeg)

### Complex Question : Reasoning

看多篇多段的文字，将信息综合起来才能得到答案，不能只进行简单的match&extract。

一些corpus（类似阅读理解？）： DROP  Hoppot QA  

#### Multiple-hop

hop的次数，change的次数，一开始作为超参数由人来决定。

[![pC7AAFs.md.png](https://s1.ax1x.com/2023/07/19/pC7AAFs.md.png)](https://imgse.com/i/pC7AAFs)

<u>*ReasoNet*</u>：这个网络在每次hop完，都要决定是否要继续hop，就是让机器自己决定是否hop

*<u>Graph Neural Network</u>*：不改变question，而是通过Graph之间的关系

### Dialogue QA

希望机器回答的不是一个问题，而是一连串问题

[![pC7A9OS.md.png](https://s1.ax1x.com/2023/07/19/pC7A9OS.md.png)](https://imgse.com/i/pC7A9OS)
